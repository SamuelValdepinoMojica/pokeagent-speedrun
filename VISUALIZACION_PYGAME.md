# üéÆ Visualizaci√≥n con Pygame Durante Entrenamiento

## Problema Resuelto

**Antes:** `--visualize` causaba **Segmentation Fault** despu√©s de ~800-3600 steps
- Usaba `PIL.Image.show()` que lanza procesos externos (xdg-open, display, etc.)
- Creaba cientos de archivos temporales PNG
- Intentaba abrir cientos de ventanas simult√°neamente
- Sistema colapsaba por agotamiento de recursos

**Ahora:** Visualizaci√≥n estable con pygame sin crashes
- ‚úÖ UNA ventana persistente de pygame
- ‚úÖ Actualizaci√≥n eficiente sin procesos externos
- ‚úÖ Control de FPS (30 FPS por defecto)
- ‚úÖ Estad√≠sticas en tiempo real (steps, episodes, rewards)
- ‚úÖ Cierre graceful (cerrar ventana detiene entrenamiento)

## Uso

### Entrenamiento CON visualizaci√≥n (m√°s lento, ~25-30 it/s)
```bash
python train_ppo.py --mode train --timesteps 100000 --visualize --n-envs 1 --state Emerald-GBAdvance/quick_start_save.state
```

### Entrenamiento SIN visualizaci√≥n (m√°s r√°pido, ~35 it/s)
```bash
python train_ppo.py --mode train --timesteps 100000 --n-envs 1 --state Emerald-GBAdvance/quick_start_save.state
```

### Ver agente entrenado (despu√©s de completar entrenamiento)
```bash
python watch_trained_agent.py --model logs/checkpoints/ppo_pokemon_100000_steps.zip --steps 2000
```

## Implementaci√≥n T√©cnica

### 1. Nuevo Callback: `PygameRenderCallback`
- Hereda de `stable_baselines3.common.callbacks.BaseCallback`
- Se ejecuta en cada step del entrenamiento
- Renderiza frame actual en ventana pygame
- Muestra estad√≠sticas overlay (steps, episodes, rewards)
- Maneja eventos de pygame (cierre de ventana)

### 2. Modificaci√≥n de `agent/drl_env.py`
**Antes:**
```python
def render(self):
    if self.render_mode == 'human':
        screenshot = self.emulator.get_screenshot()
        screenshot.show()  # ‚ùå Lanza procesos externos
```

**Despu√©s:**
```python
def render(self):
    if self.render_mode == 'human':
        screenshot = self.emulator.get_screenshot()
        return np.array(screenshot)  # ‚úÖ Retorna array para pygame
```

### 3. Integraci√≥n en `train_ppo.py`
- Import de pygame y numpy
- Clase `PygameRenderCallback` con rendering eficiente
- Callbacks condicionales (pygame solo si `--visualize`)
- Unwrapping correcto de Monitor wrapper

## Caracter√≠sticas de la Ventana Pygame

### Tama√±o
- 720x480 pixels (3x escala del GBA original 240x160)

### Estad√≠sticas Mostradas
- **Steps:** Total de pasos de entrenamiento
- **Episodes:** Episodios completados
- **Avg Reward:** Promedio de reward de √∫ltimos 10 episodios
- **Episode Length:** Longitud del episodio actual

### Control de FPS
- **30 FPS:** Balance entre fluidez y rendimiento
- Configurable en el c√≥digo (par√°metro `fps`)

### Cierre
- Cerrar ventana pygame ‚Üí Detiene entrenamiento gracefully
- Guarda modelo con sufijo `_interrupted`

## Comparaci√≥n de Rendimiento

| Modo | it/s | Tiempo 100k steps | Ventana | Estabilidad |
|------|------|-------------------|---------|-------------|
| Sin visualizaci√≥n | ~35 it/s | ~48 minutos | ‚ùå No | ‚úÖ 100% estable |
| Con pygame (nuevo) | ~25-30 it/s | ~60-70 minutos | ‚úÖ S√≠ | ‚úÖ 100% estable |
| Con PIL.show() (viejo) | ~33 it/s | ‚ùå Crash en 800-3600 steps | ‚ùå M√∫ltiples | ‚ùå CRASH |

## Diferencias: train_ppo.py vs watch_trained_agent.py

### `train_ppo.py --visualize` (NUEVO)
- **Prop√≥sito:** Ver entrenamiento en tiempo real
- **Framework:** Pygame con callback de Stable-Baselines3
- **Velocidad:** 25-30 it/s (un poco m√°s lento)
- **Estad√≠sticas:** Steps, episodes, avg reward
- **Uso:** Durante entrenamiento activo

### `watch_trained_agent.py`
- **Prop√≥sito:** Ver agente YA entrenado jugando
- **Framework:** Pygame standalone
- **Velocidad:** 60 FPS (m√°s fluido)
- **Estad√≠sticas:** Reward acumulado, acci√≥n actual
- **Uso:** Despu√©s de completar entrenamiento

## Verificaci√≥n de Funcionamiento

### Test Exitoso (15000 steps)
```bash
python train_ppo.py --mode train --timesteps 15000 --visualize --n-envs 1 --state Emerald-GBAdvance/quick_start_save.state
```

**Resultado:**
- ‚úÖ Exit Code: 0 (√©xito)
- ‚úÖ Sin Segmentation Fault
- ‚úÖ Ventana pygame funcionando correctamente
- ‚úÖ ~29-30 it/s estable
- ‚úÖ Warnings de "Map buffer corruption" son normales (no causan crash)

## Notas Importantes

### ‚ö†Ô∏è `--visualize` solo funciona con `n_envs=1`
Si intentas `--visualize --n-envs 2`, autom√°ticamente se cambia a `n_envs=1`.

### ‚ö†Ô∏è Map buffer corruption warnings
Los warnings de "Map buffer corruption" son **normales** y **NO causan crashes**:
- Aparecen cuando el juego cambia de mapa/ubicaci√≥n
- El c√≥digo se recupera autom√°ticamente
- No afectan el entrenamiento

### ‚ö†Ô∏è Rendimiento
Visualizaci√≥n reduce velocidad ~15-20%:
- Sin visualizaci√≥n: 35 it/s
- Con visualizaci√≥n: 25-30 it/s
- Para entrenamiento largo (1M steps), usa sin visualizaci√≥n

## Recomendaci√≥n de Uso

### Para Experimentaci√≥n/Debug (cortos)
```bash
# Ver qu√© hace el agente (5k-20k steps)
python train_ppo.py --mode train --timesteps 10000 --visualize --n-envs 1 --state Emerald-GBAdvance/quick_start_save.state
```

### Para Entrenamiento Serio (largos)
```bash
# Sin visualizaci√≥n para m√°xima velocidad (100k-1M steps)
python train_ppo.py --mode train --timesteps 1000000 --n-envs 1 --state Emerald-GBAdvance/quick_start_save.state

# Luego ver con watch_trained_agent.py
python watch_trained_agent.py --model logs/checkpoints/ppo_pokemon_1000000_steps.zip --steps 5000
```

## Cr√©ditos

- Implementaci√≥n basada en `watch_trained_agent.py` existente
- Adaptado para funcionar como callback de Stable-Baselines3
- Resuelve el problema de resource exhaustion de PIL.Image.show()
