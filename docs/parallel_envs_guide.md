# ðŸš€ GuÃ­a: MÃºltiples Ambientes Paralelos (VecEnv)

## âœ… SÃ, Ya EstÃ¡ Implementado!

El cÃ³digo de `train_ppo.py` **ya soporta mÃºltiples ambientes en paralelo** usando `VecEnv` de Stable Baselines3.

---

## ðŸŽ¯ Â¿QuÃ© Son los Ambientes Paralelos?

En lugar de entrenar con **1 juego a la vez**, puedes entrenar con **N juegos simultÃ¡neos**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Game 1    â”‚  â”‚   Game 2    â”‚  â”‚   Game 3    â”‚  â”‚   Game 4    â”‚
â”‚  (Emulator) â”‚  â”‚  (Emulator) â”‚  â”‚  (Emulator) â”‚  â”‚  (Emulator) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                â†“                â†“                â†“
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PPO Agent     â”‚
                    â”‚  (Aprende de    â”‚
                    â”‚   todos a la    â”‚
                    â”‚     vez)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸ“Š Ventajas:

1. **MÃ¡s rÃ¡pido:** 4 ambientes = recolectas 4x mÃ¡s experiencia por segundo
2. **MÃ¡s diverso:** Cada juego puede estar en estado diferente
3. **Mejor entrenamiento:** MÃ¡s variedad de situaciones

### âš ï¸ Desventajas:

1. **MÃ¡s RAM:** Cada ambiente necesita ~500MB
2. **MÃ¡s CPU:** Cada emulador consume CPU
3. **No visualizable:** Solo puedes ver 1 juego a la vez

---

## ðŸ”§ CÃ³mo Usar MÃºltiples Ambientes

### OpciÃ³n 1: Desde lÃ­nea de comandos

```bash
# 1 ambiente (por defecto)
python train_ppo.py --mode train --timesteps 100000 --n-envs 1

# 4 ambientes (4x mÃ¡s rÃ¡pido)
python train_ppo.py --mode train --timesteps 100000 --n-envs 4

# 8 ambientes (si tienes RAM suficiente)
python train_ppo.py --mode train --timesteps 100000 --n-envs 8

# Con visualizaciÃ³n (solo funciona con 1 ambiente)
python train_ppo.py --mode train --timesteps 100000 --n-envs 1 --visualize
```

### OpciÃ³n 2: En el cÃ³digo

```python
from train_ppo import train_ppo

# 4 ambientes paralelos
train_ppo(
    rom_path="Emerald-GBAdvance/rom.gba",
    initial_state_path="Emerald-GBAdvance/quick_start_save.state",
    total_timesteps=1_000_000,
    n_envs=4  # â† AQUÃ especificas cuÃ¡ntos
)
```

---

## ðŸ“Š ComparaciÃ³n de Rendimiento

### Con Lightweight State Reader (239 FPS por ambiente):

| n_envs | FPS Total | Steps/sec | Time para 1M steps |
|--------|-----------|-----------|-------------------|
| 1      | 239 FPS   | ~40 steps/sec  | ~7 horas |
| 2      | 478 FPS   | ~80 steps/sec  | ~3.5 horas |
| 4      | 956 FPS   | ~160 steps/sec | ~1.7 horas |
| 8      | 1912 FPS  | ~320 steps/sec | ~52 minutos |

**Nota:** Los nÃºmeros reales dependen de tu CPU/RAM

### Requisitos de RAM:

| n_envs | RAM Estimada |
|--------|--------------|
| 1      | ~1 GB        |
| 2      | ~2 GB        |
| 4      | ~4 GB        |
| 8      | ~8 GB        |

---

## ðŸ’¡ Recomendaciones

### Para tu sistema:

```bash
# Ver RAM disponible
free -h

# Ver CPU cores
nproc
```

**RecomendaciÃ³n:**
- **4-8 GB RAM:** Usa `n_envs=4`
- **8-16 GB RAM:** Usa `n_envs=8`
- **16+ GB RAM:** Usa `n_envs=16`
- **CPU cores:** Usa aproximadamente `n_envs = num_cores - 2`

### Durante desarrollo/debugging:

```bash
# Usa 1 ambiente con visualizaciÃ³n para ver quÃ© hace
python train_ppo.py --mode train --timesteps 10000 --n-envs 1 --visualize
```

### Para training real:

```bash
# Usa 4-8 ambientes sin visualizaciÃ³n
python train_ppo.py --mode train --timesteps 1000000 --n-envs 4
```

---

## ðŸ” CÃ³digo Relevante

### CÃ³mo se Crean los Ambientes:

```python
# En train_ppo.py, lÃ­neas 100-105:

if n_envs == 1:
    # Un solo ambiente (puede tener visualizaciÃ³n)
    env = DummyVecEnv([make_env(rom_path, initial_state_path, rank=0, visualize=visualize)])
else:
    # MÃºltiples ambientes (todos headless)
    env_fns = [make_env(rom_path, initial_state_path, rank=i, visualize=False) for i in range(n_envs)]
    env = DummyVecEnv(env_fns)
```

### Cada Ambiente Tiene:

```python
def make_env(rom_path, state_path, rank=0, visualize=False):
    """Crea un ambiente individual"""
    def _init():
        env = PokemonEmeraldEnv(
            rom_path=rom_path,
            initial_state_path=state_path,
            render_mode='human' if visualize else None,  # Solo env 0 puede visualizar
            max_steps=10000,
            frame_skip=6
        )
        env = Monitor(env, f"./logs/monitor_{rank}")  # Cada uno tiene su propio log
        return env
    return _init
```

---

## ðŸ§ª Prueba de Concepto

### Paso 1: Probar con 1 ambiente

```bash
python train_ppo.py --mode train --timesteps 10000 --n-envs 1
```

**Tiempo esperado:** ~4 minutos (con lightweight reader)

### Paso 2: Probar con 4 ambientes

```bash
python train_ppo.py --mode train --timesteps 10000 --n-envs 4
```

**Tiempo esperado:** ~1 minuto (4x mÃ¡s rÃ¡pido)

### Paso 3: Comparar logs

```bash
# Ver estadÃ­sticas de cada ambiente
tensorboard --logdir=./tensorboard_logs
```

VerÃ¡s mÃ©tricas separadas para cada ambiente:
- `rollout/ep_rew_mean_env_0`
- `rollout/ep_rew_mean_env_1`
- `rollout/ep_rew_mean_env_2`
- `rollout/ep_rew_mean_env_3`

---

## âš™ï¸ ParÃ¡metros del CLI

El script `train_ppo.py` acepta el flag `--n-envs`:

```bash
python train_ppo.py --help

Options:
  --mode {train,test,benchmark}
  --timesteps INT              Total training timesteps (default: 1000000)
  --n-envs INT                 Number of parallel environments (default: 4)
  --frame-skip INT             Frames per action (default: 6)
  --model PATH                 Load existing model
  --state PATH                 Initial save state
  --visualize                  Show pygame window (only with n-envs=1)
```

---

## ðŸ› Troubleshooting

### Error: "Out of memory"

**SoluciÃ³n:** Reduce `n_envs`
```bash
python train_ppo.py --mode train --timesteps 100000 --n-envs 2
```

### Error: "Too many open files"

**SoluciÃ³n:** Aumenta el lÃ­mite del sistema
```bash
ulimit -n 4096
python train_ppo.py --mode train --timesteps 100000 --n-envs 4
```

### Warning: "visualize=True only works with n_envs=1"

**SoluciÃ³n:** El cÃ³digo automÃ¡ticamente ajusta `n_envs=1` si intentas visualizar con mÃºltiples ambientes.

---

## ðŸ“ˆ Benchmark RÃ¡pido

Para probar cuÃ¡ntos ambientes soporta tu sistema:

```bash
# Test con 1 ambiente
time python train_ppo.py --mode train --timesteps 1000 --n-envs 1

# Test con 4 ambientes
time python train_ppo.py --mode train --timesteps 1000 --n-envs 4

# Test con 8 ambientes
time python train_ppo.py --mode train --timesteps 1000 --n-envs 8
```

Compara los tiempos y uso de RAM.

---

## ðŸŽ¯ Ejemplo Completo de Training

```bash
# Training completo con 4 ambientes paralelos
python train_ppo.py \
    --mode train \
    --timesteps 1000000 \
    --n-envs 4 \
    --frame-skip 6 \
    --state Emerald-GBAdvance/quick_start_save.state

# Resultado esperado:
# - Tiempo: ~1.7 horas (con lightweight reader + 4 envs)
# - Modelos guardados cada 10k steps en logs/checkpoints/
# - TensorBoard logs en tensorboard_logs/
# - Monitoreo en tiempo real con: tensorboard --logdir=./tensorboard_logs
```

---

## âœ… VerificaciÃ³n

Para confirmar que estÃ¡ usando mÃºltiples ambientes:

```bash
# Durante training, en otra terminal:
watch -n 1 'ps aux | grep python | grep train_ppo'

# DeberÃ­as ver mÃºltiples procesos mGBA si n_envs > 1
ps aux | grep mgba
```

---

## ðŸ’¡ Tips Finales

1. **Desarrollo:** Usa `n_envs=1 --visualize` para ver quÃ© hace el agente
2. **Training rÃ¡pido:** Usa `n_envs=4` (buen balance RAM/velocidad)
3. **Training Ã³ptimo:** Usa `n_envs=8` (si tienes 8+ GB RAM)
4. **ProducciÃ³n:** Usa `n_envs=16` (si tienes servidor potente)

**Regla de oro:** `n_envs = CPU_cores - 2` (deja 2 cores para el sistema)

---

## ðŸš€ Comando Recomendado para Ti

BasÃ¡ndome en un sistema tÃ­pico (8 GB RAM, 4-8 CPU cores):

```bash
# Training Ã³ptimo con mÃºltiples ambientes
python train_ppo.py \
    --mode train \
    --timesteps 1000000 \
    --n-envs 4 \
    --frame-skip 6 \
    --state Emerald-GBAdvance/quick_start_save.state

# Monitorear en otra terminal:
tensorboard --logdir=./tensorboard_logs --port 6006
# Abrir: http://localhost:6006
```

**Tiempo estimado:** ~1.7 horas para 1M steps (vs 7 horas con 1 ambiente)

---

**Â¿Listo para empezar el training con mÃºltiples ambientes?** ðŸŽ®
